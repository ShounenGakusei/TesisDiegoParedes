{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e386f507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py==1.0.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: argon2-cffi==21.3.0 in c:\\users\\shounen\\anaconda3\\envs\\tenv\\lib\\site-packages (from -r requirements.txt (line 2)) (21.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in c:\\users\\shounen\\anaconda3\\envs\\tenv\\lib\\site-packages (from -r requirements.txt (line 3)) (21.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\shounen\\anaconda3\\envs\\tenv\\lib\\site-packages (from -r requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: attrs==21.4.0 in c:\\users\\shounen\\anaconda3\\envs\\tenv\\lib\\site-packages (from -r requirements.txt (line 5)) (21.4.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in c:\\users\\shounen\\anaconda3\\envs\\tenv\\lib\\site-packages (from -r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: bleach==4.1.0 in c:\\users\\shounen\\anaconda3\\envs\\tenv\\lib\\site-packages (from -r requirements.txt (line 7)) (4.1.0)\n",
      "Collecting cachetools==5.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting Cartopy==0.18.0\n",
      "  Using cached Cartopy-0.18.0.tar.gz (14.4 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\Shounen\\anaconda3\\envs\\tenv\\python.exe' -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Shounen\\\\AppData\\\\Local\\\\Temp\\\\pip-install-7v0lvo2m\\\\cartopy_3d2a0d4faf794352843444e5b5d6baaa\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Shounen\\\\AppData\\\\Local\\\\Temp\\\\pip-install-7v0lvo2m\\\\cartopy_3d2a0d4faf794352843444e5b5d6baaa\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\Shounen\\AppData\\Local\\Temp\\pip-pip-egg-info-bzd5rgf7'\n",
      "         cwd: C:\\Users\\Shounen\\AppData\\Local\\Temp\\pip-install-7v0lvo2m\\cartopy_3d2a0d4faf794352843444e5b5d6baaa\\\n",
      "    Complete output (3 lines):\n",
      "    C:\\Users\\Shounen\\AppData\\Local\\Temp\\pip-install-7v0lvo2m\\cartopy_3d2a0d4faf794352843444e5b5d6baaa\\setup.py:104: UserWarning: Unable to determine GEOS version. Ensure you have 3.3.3 or later installed, or installation may fail.\n",
      "      warnings.warn(\n",
      "    Proj 4.9.0 must be installed.\n",
      "    ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/46/c1/04e50c9986842f00f7db0e7a65caa896840050d7328f74e5b7437aa01179/Cartopy-0.18.0.tar.gz#sha256=7ffa317e8f8011e0d965a3ef1179e57a049f77019867ed677d49dcc5c0744434 (from https://pypi.org/simple/cartopy/) (requires-python:>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n",
      "ERROR: Could not find a version that satisfies the requirement Cartopy==0.18.0 (from versions: 0.11.0, 0.12.0.4, 0.12.0.5, 0.13.0, 0.13.1, 0.14.0, 0.14.2, 0.15.1, 0.16.0, 0.17.0, 0.18.0b1, 0.18.0b2, 0.18.0rc1, 0.18.0, 0.19.0rc1, 0.19.0.post1, 0.20.0, 0.20.1, 0.20.2)\n",
      "ERROR: No matching distribution found for Cartopy==0.18.0\n"
     ]
    }
   ],
   "source": [
    "#Version 3.9 de Python (Conda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693d6b52",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'netCDF4'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_465552/1597871689.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mnetCDF4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum2date\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcartopy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcrs\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mccrs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcartopy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mcf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'netCDF4'"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset, num2date\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import re\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e25220c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 108, 108, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 54, 54, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 52, 52, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 26, 26, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2359360   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,415,754\n",
      "Trainable params: 2,415,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#El modelo solo considera en input_shape(x,x,1), el 1 se puede cambiar para abarcar mas canales de imagenes satelitales\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(110, 110, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "#-Visualizacion\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "477f5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se le da un tensor de 4 dimensiones\n",
    "#[0] =  dato de precipitacion\n",
    "#[1] = Punto de la estacion (Longitud)\n",
    "#[2] = Punto de la estacion (Latitud)\n",
    "#[3] = El nombre del archivo que contiene la imagen satelital\n",
    "\n",
    "\n",
    "def leerImagenArea(tensor):\n",
    "    \"\"\"\n",
    "    Los archivos se deben encontrar en carpetas ordenadas : ../GOES/{producto}/{año}/{mes}/archivo.nc\n",
    "    \n",
    "    EJEMPLO : path_base + GOES/C8/2019/02/G16_C08_Cyl_20190210-1600.nc\n",
    "    \"\"\"\n",
    "    #Se define por defecto el path base (Temporal)\n",
    "    path_base  =  'C:/Users/Shounen/Desktop/Ciclo XI/Tesis 2'\n",
    "    \n",
    "    \n",
    "    \n",
    "    #El ancho y alto sera el margen que se dara desde el punto de origen (estacion)\n",
    "    #Esta en grados (1 grado == 100Km) - (Temporal)\n",
    "    ancho=1\n",
    "    alto=1\n",
    "    \n",
    "    \n",
    "    filename = tensor.numpy()[3].decode('UTF-8')\n",
    "    origen = [float(tensor.numpy()[1].decode('UTF-8')),float(tensor.numpy()[2].decode('UTF-8'))]   \n",
    "    \n",
    "    try:\n",
    "        ds = Dataset(filename)\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "    # convierte el tiempo de formato numerico a formato fecha y hora de python\n",
    "    #date = num2date(ds.variables['time'][:], ds.variables['time'].units, only_use_cftime_datetimes=False, only_use_python_datetimes=True)\n",
    "    \n",
    "    # convierte el formato de la variable de Int16 a Float32 y guarda el resultado\n",
    "    field = ds.variables['CMI'][:].data.astype(np.float32)/100.0\n",
    "    \n",
    "    # obtiene las coordenadas de los pixeles\n",
    "    lon = ds.variables['longitude'][:].data\n",
    "    lat = ds.variables['latitude'][:].data    \n",
    "    \n",
    "    #Se define el margen para recortar la imagen satelital\n",
    "    maxLon=origen[0]+ancho\n",
    "    minLon=origen[0]-ancho\n",
    "    maxLat=origen[1]+alto\n",
    "    minLat=origen[1]-alto\n",
    "    \n",
    "    #Booleanos que ayudarán a buscar el margen\n",
    "    altoMin = False\n",
    "    altoMax = False\n",
    "    \n",
    "    \n",
    "    #Inicializamos los \"indices\"\n",
    "    lom = 0\n",
    "    loM = 0\n",
    "    lam = 0\n",
    "    laM = 0\n",
    "    \n",
    "    \"\"\"\n",
    "    Tener en cuenta que el arreglo de longitudes (lon) esta ordenado de manera creciente,\n",
    "    mientras que el de latitudes (lat) esta de manera decreciente\n",
    "    \"\"\"    \n",
    "    for i in range(0,len(lon)):\n",
    "        if lon[i]>=minLon and not altoMin:\n",
    "            altoMin = True\n",
    "            lom = i\n",
    "        if lon[i]<=maxLon:\n",
    "            loM = i\n",
    "                \n",
    "    for j in range(0,len(lat)):\n",
    "        if lat[j]>=minLat:    \n",
    "            laM = j\n",
    "        if lat[j]<=maxLat and not altoMax:\n",
    "            altoMax = True\n",
    "            lam = j           \n",
    "    \n",
    "    #return lon[lom:loM],lat[lam:laM], field[lam:laM,lom:loM]    \n",
    "    return field[lam:laM,lom:loM]\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81837b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20912\n",
      "[44800, 'OCROS', -77.39676, -10.40312, nan, nan, \"['2019', '02', '10']\", 'C:/Users/Shounen/Desktop/Ciclo XI/Tesis 2/GOES/C8/2019/02/G16_C08_Cyl_20190210-1600.nc']\n"
     ]
    }
   ],
   "source": [
    "#Se obtiene los datos de precipitaciones desde el archivo CSV\n",
    "datosFile = 'C:/Users/Shounen/Desktop/Ciclo XI/Tesis 2/SENAMHI/X4AD000C8.csv'\n",
    "\n",
    "#Se lee desde la fila 44800, pues dede ahí comienza los datos del año 2019\n",
    "pdata = pd.read_csv(datosFile, na_values = \"0\", skiprows = 44800)\n",
    "dList = pdata.values.tolist()\n",
    "\n",
    "\n",
    "#-Visualizacion\n",
    "print(len(dList))\n",
    "print(dList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d9c2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se recorta la lista de datos para hacer pruebas\n",
    "dList = dList[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7378891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4)\n",
      "['0.0' '-77.39676' '-10.40312'\n",
      " 'C:/Users/Shounen/Desktop/Ciclo XI/Tesis 2/GOES/C8/2019/02/G16_C08_Cyl_20190210-1600.nc']\n"
     ]
    }
   ],
   "source": [
    "#Con los datos del CSV, se obtiene solo lo necesario para el entrenamiento\n",
    "#x[5] = dato de precipitacion\n",
    "#x[2] = Estacion (Longitud)\n",
    "#x[3] = Estacion (Latitud)\n",
    "#x[7] = Nombre del archivo de la imagen satelital\n",
    "imagenT = []\n",
    "for x in dList: \n",
    "    \n",
    "    if pd.isna(x[5]):\n",
    "        datoTemp = 0.0\n",
    "    else:\n",
    "        datoTemp = x[5]\n",
    "    imagenT.append([datoTemp,x[2],x[3],x[7]])\n",
    "\n",
    "#Se convierte en numpy.array la lista\n",
    "imagenT = np.array(imagenT)\n",
    "imagenT  = np.nan_to_num(imagenT)\n",
    "\n",
    "\n",
    "#-Visualizacion\n",
    "print(imagenT.shape)\n",
    "print(imagenT[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80a05640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'0.0' b'-77.39676' b'-10.40312'\n",
      " b'C:/Users/Shounen/Desktop/Ciclo XI/Tesis 2/GOES/C8/2019/02/G16_C08_Cyl_20190210-1600.nc']\n"
     ]
    }
   ],
   "source": [
    "#Se separa el dataset (datos entrenamiento y validacion)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(imagenT)\n",
    "\n",
    "train_size = int(len(imagenT)*0.8)\n",
    "train_ds = dataset.take(train_size)\n",
    "test_ds = dataset.skip(train_size)\n",
    "\n",
    "\n",
    "#-Visualizacion\n",
    "for d in train_ds.take(1):\n",
    "    print(d.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c38bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Servira para obtener el arreglo que representa la imagen satelital (recortada) usando el nombre del archivo\n",
    "def _parse_function(dato):\n",
    "    #Se llama a la funcion leerImagenArea con el tensor, retorna el arreglo que representa la imagen\n",
    "    y = tf.py_function(func=leerImagenArea, inp=[dato], Tout=tf.float32)   \n",
    "    \n",
    "    #Retorna el arreglo (imagen) , dato de precipitacion\n",
    "    return  y, float(dato[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dce069d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[244.35 244.3  244.35 ... 242.7  242.87 242.95]\n",
      " [244.3  244.51 244.43 ... 242.74 242.99 242.99]\n",
      " [244.43 244.51 244.56 ... 242.74 242.91 243.08]\n",
      " ...\n",
      " [226.43 227.61 228.04 ... 239.23 239.4  239.32]\n",
      " [226.43 227.61 228.04 ... 239.32 239.28 239.23]\n",
      " [222.59 221.66 223.31 ... 239.23 239.15 239.32]], shape=(110, 110), dtype=float32)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Probamos que funcione correctamente la funcion de parseo\n",
    "for xTemp in dataset.take(1):\n",
    "    xImg,xDato = _parse_function(xTemp)\n",
    "    \n",
    "#-Visualizacion\n",
    "print(xImg)\n",
    "print(xDato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71bd7d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>\n",
      "<MapDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "#Se les aplica la funcion de parseo al dataset de entrenamiento y validacion\n",
    "train_dsX = train_ds.map(_parse_function)\n",
    "test_dsX = test_ds.map(_parse_function)\n",
    "\n",
    "#-Visualizacion\n",
    "print(train_dsX)\n",
    "print(test_dsX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ae6c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos el prefetch en los datos de validacion y entrenamiento\n",
    "#AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "#train_dsX = train_dsX.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "#test_dsX = test_dsX.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a0d6d46",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\Tesis\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\Tesis\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\Tesis\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\Tesis\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\Tesis\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\Tesis\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 212, in __call__\n        batch_dim = tf.shape(y_t)[0]\n\n    ValueError: slice index 0 of dimension 0 out of bounds. for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](Shape, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_175324/3269561373.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m               metrics=['accuracy'])\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_dsX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtest_dsX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\envs\\Tesis\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Tesis\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36mautograph_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m           \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint:disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1146\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"ag_error_metadata\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1147\u001B[1;33m               \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1148\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m               \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\Tesis\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\Tesis\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\Tesis\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\Tesis\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\Tesis\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Shounen\\anaconda3\\envs\\Tesis\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 212, in __call__\n        batch_dim = tf.shape(y_t)[0]\n\n    ValueError: slice index 0 of dimension 0 out of bounds. for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](Shape, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_dsX, epochs=1,validation_data=test_dsX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef341b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos lso resultados\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-64018049",
   "language": "python",
   "display_name": "PyCharm (pythonProject1)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}