{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8aa67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d0bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d5be9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a709e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38401a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe66ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manejo de Datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Machine learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Librerias estandar (Extras)\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98f7bd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5339504a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeefdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Metodos para realizar el entrenamient - evaluacion del modelo\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a24f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea un modelo con dimensiones input (dimTime,W,H,dimCanal) y output(output)\n",
    "def crearModelo(dimTime,W,H,dimCanal, output):\n",
    "    \n",
    "    print(f\"Se creo un modelo con input ({dimTime}, {W},{H}, {dimCanal}) y output({output})\")\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv3D(32, (3, 3,3), activation='relu', input_shape=(dimTime, W, H, dimCanal)))\n",
    "    model.add(layers.MaxPooling3D((2, 2,2)))\n",
    "    #model.add(layers.Conv3D(128, (3, 3,3), activation='relu'))\n",
    "    #model.add(layers.MaxPooling3D((2, 2,2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(output))\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3676d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se realiza una comprobacion que las imagenes PNG para las fechas de los datos de precipitacion existan de manera local\n",
    "#En caso no encontrarlos, elimina el dato de precipitacion del dataset\n",
    "def comprobarFrames(dfOrignial, path_base, products, times, delete=1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    dfTotal = pd.unique(dfOrignial['fecha'])\n",
    "\n",
    "    no_fecha = []\n",
    "    for fecha in dfTotal:\n",
    "        year, month, day, hour = fecha.split('-')\n",
    "\n",
    "        existe = True\n",
    "        for p in products:\n",
    "            for t in range(len(times)):\n",
    "                filename = f'{path_base}comprimido/{fecha}/{fecha}_{p}_{t}.csv'\n",
    "                existe = os.path.exists(filename)\n",
    "                if not existe:\n",
    "                    break\n",
    "            if not existe:\n",
    "                break\n",
    "        if not existe:\n",
    "            no_fecha.append(fecha)\n",
    "\n",
    "    if delete:\n",
    "        antes = len(dfOrignial)\n",
    "        df2 = dfOrignial[~dfOrignial['fecha'].isin(no_fecha)]\n",
    "        despues = len(df2)\n",
    "        print(f'{antes - despues}/{antes} datos eliminados: No se encontraron los archivos de imagenes satelitales')\n",
    "    else:\n",
    "        df2 = dfOrignial\n",
    "\n",
    "    print(\"Tiempo tomado en verificar datos: %.2fs\" % (time.time() - start_time))\n",
    "    return df2, no_fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be163e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Del dataset guardamos los datos mas importantes en una columna para facilitar su lectura\n",
    "def obtenerDir(row):\n",
    "    fecha = row['fecha']\n",
    "\n",
    "    year, month, day, hour = fecha.split('-')\n",
    "    # filename = f'{path_base}comprimido/{year}_{month}_{day}/{hour}/'\n",
    "    return f\"{row['XO']}--{row['XA']}--{fecha}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2eb96509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lee el archivo \"filename\" de datos de precipitacion y\n",
    "#regresa un df que facilite la lectura del dataset para el entrenmaiento\n",
    "def obtenerDatos(filename):\n",
    "    start_time = time.time()\n",
    "    pdata = pd.read_csv(filename)\n",
    "\n",
    "    # Quitamos los valores NA\n",
    "    pdata = pdata[pdata['dato'].notna()]\n",
    "\n",
    "    # Definimos un solo tipo (str) pora asi poder convertirlo a tensor\n",
    "    pdata = pdata.astype({\"dato\": str, \"XO\": str, \"XA\": str, \"fecha\": str})\n",
    "\n",
    "    #Definimos la nueva columna para guardar el XO, XA y fecha\n",
    "    pdata['imagen'] = pdata.apply(obtenerDir, axis=1)\n",
    "\n",
    "    # Seleccionamos solo las columnas necesarias :\n",
    "    # precipitacion, Estacion (Longitud), Estacion (Latitud), Fecha (año-mes-dia-hora)\n",
    "    pdataX = pdata.loc[:, ['atipico90', 'imagen', 'fecha']]\n",
    "    pdataX = pdataX.astype({\"atipico90\": str, \"imagen\": str, \"fecha\": str})\n",
    "\n",
    "    # Barajeamos los datos\n",
    "    pdataX = shuffle(pdataX)\n",
    "\n",
    "    print(f'{len(pdataX)} datos leidos')\n",
    "    print(\"Tiempo tomado en leer datos: %.2fs\" % (time.time() - start_time))\n",
    "    return pdataX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cefc3a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforma el filename de la imagen (tensor) en un arreglo de numeros\n",
    "def read_png_file(item, value, size, path_base, products, times):\n",
    "    # imagenData[0] = XO\n",
    "    # imagenData[1] = XA\n",
    "    # imagenData[2] = Fecha\n",
    "    imagenData = tf.strings.split(item, sep='--')\n",
    "\n",
    "    size = int(size / 2)\n",
    "    timeJoin = []\n",
    "    for j in range(len(times)):\n",
    "        filename = path_base + 'PNG/' + imagenData[2] + '/' + imagenData[2] + '_' + str(j) + '.png'\n",
    "        image_string = tf.io.read_file(filename)\n",
    "\n",
    "        img_decoded = tf.io.decode_png(image_string, dtype=tf.uint16, channels=3)\n",
    "\n",
    "        timeJoin.append(img_decoded[int(imagenData[0]) - size:int(imagenData[0]) + size,\n",
    "                             int(imagenData[1]) - size:int(imagenData[1]) + size,:])\n",
    "\n",
    "    img = tf.stack(timeJoin, axis=0)\n",
    "\n",
    "    return img, int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010fb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Realizamos el flujo de entrenmaiento\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d01fc2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables generales\n",
    "\n",
    "#Path_base debe ser completo, se usará para comprobar si existen las imagenes satelitales descargadas\n",
    "#path_base = 'C:/Users/Shounen/Desktop/Ciclo XI/Tesis 2/GOES/'\n",
    "path_base = 'F:/GOES/'\n",
    "\n",
    "#Productos de las imagenes satelitales (C08, C07 o C13, C02)\n",
    "products = ['C07','C08','C13']\n",
    "times = ['10','20','30','40','50','00']\n",
    "\n",
    "#W, H son el tamaño que se tomara de la matriz, teniendo como centro la cordenada de la estacion\n",
    "#dimT se refiere a intervalos de tiempo que se toamran las imagenes (min 15,30 o 45).\n",
    "#Tambien cuenta el tiempo 00, asi que dimT > 1\n",
    "dimT = len(times)\n",
    "\n",
    "W = 110\n",
    "H = 110\n",
    "\n",
    "#Representa el output del modelo (2 clases)\n",
    "#1 = Precipitacion extrema\n",
    "#0 = Precipitacion normal\n",
    "dimOutput = 2\n",
    "\n",
    "#El margen servira para recortar la imagen [alto, ancho] desde el punto de origen (estacion)\n",
    "margen = [W,H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3db4f3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92786 datos leidos\n",
      "Tiempo tomado en leer datos: 1.30s\n"
     ]
    }
   ],
   "source": [
    "#Leemos los datos del archivo\n",
    "#dfOrignial = obtenerDatos('2021_umbral.csv')\n",
    "dfOrignial = obtenerDatos('2020_umbral.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c198e7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atipico90</th>\n",
       "      <th>imagen</th>\n",
       "      <th>fecha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75903</th>\n",
       "      <td>0</td>\n",
       "      <td>391--531--2020-10-06-16</td>\n",
       "      <td>2020-10-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77423</th>\n",
       "      <td>0</td>\n",
       "      <td>391--531--2020-12-14-05</td>\n",
       "      <td>2020-12-14-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26120</th>\n",
       "      <td>0</td>\n",
       "      <td>281--379--2020-04-30-22</td>\n",
       "      <td>2020-04-30-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21225</th>\n",
       "      <td>0</td>\n",
       "      <td>540--822--2020-06-30-22</td>\n",
       "      <td>2020-06-30-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68387</th>\n",
       "      <td>0</td>\n",
       "      <td>419--592--2020-05-08-22</td>\n",
       "      <td>2020-05-08-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27706</th>\n",
       "      <td>0</td>\n",
       "      <td>281--379--2020-07-06-03</td>\n",
       "      <td>2020-07-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>0</td>\n",
       "      <td>724--294--2020-10-19-16</td>\n",
       "      <td>2020-10-19-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66108</th>\n",
       "      <td>0</td>\n",
       "      <td>491--700--2020-11-25-11</td>\n",
       "      <td>2020-11-25-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51181</th>\n",
       "      <td>0</td>\n",
       "      <td>539--356--2020-12-02-15</td>\n",
       "      <td>2020-12-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13439</th>\n",
       "      <td>0</td>\n",
       "      <td>418--594--2020-05-02-05</td>\n",
       "      <td>2020-05-02-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91524 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      atipico90                   imagen          fecha\n",
       "75903         0  391--531--2020-10-06-16  2020-10-06-16\n",
       "77423         0  391--531--2020-12-14-05  2020-12-14-05\n",
       "26120         0  281--379--2020-04-30-22  2020-04-30-22\n",
       "21225         0  540--822--2020-06-30-22  2020-06-30-22\n",
       "68387         0  419--592--2020-05-08-22  2020-05-08-22\n",
       "...         ...                      ...            ...\n",
       "27706         0  281--379--2020-07-06-03  2020-07-06-03\n",
       "4788          0  724--294--2020-10-19-16  2020-10-19-16\n",
       "66108         0  491--700--2020-11-25-11  2020-11-25-11\n",
       "51181         0  539--356--2020-12-02-15  2020-12-02-15\n",
       "13439         0  418--594--2020-05-02-05  2020-05-02-05\n",
       "\n",
       "[91524 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comprobamos que existan las imagenes (PNG) para todos los dato\n",
    "dfVerificado, no_fecha = comprobarFrames(dfOrignial,path_base,products, times,1)\n",
    "dfVerificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fea4dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "####Se entrenara con 2 products (C08,C07)#####\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e91a3630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "['0', '391--531--2020-10-06-16', '2020-10-06-16']\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos algunos para las pruebas\n",
    "dfSplit = dfVerificado[0:100]\n",
    "datasetList = dfSplit.values.tolist()\n",
    "\n",
    "#-Visualizacion\n",
    "print(len(datasetList))\n",
    "print(datasetList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ad01f7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=(TensorSpec(shape=(6, 110, 110, 3), dtype=tf.int16, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Procemos los dataset en tensores para facilitar el entrenamiento\n",
    "train, test = train_test_split(dfSplit, test_size=0.2)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train['imagen'].tolist(),train['atipico90'].tolist()))           \n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((test['imagen'].tolist(),test['atipico90'].tolist()))           \n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x ,y : read_png_file(x,y,110,path_base,products,times))\n",
    "val_dataset = val_dataset.map(lambda x ,y : read_png_file(x,y,110,path_base,products,times))\n",
    "\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4150c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables para el entrenmianeto\n",
    "batch_size = 100\n",
    "epocas = 7\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02c47c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se creo un modelo con input (6, 110,110, 3) y output(2)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 4, 108, 108, 32)   2624      \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 2, 54, 54, 32)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 186624)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11944000  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,946,754\n",
      "Trainable params: 11,946,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Creamos el modelo\n",
    "modelo = crearModelo(dimT, W,H, len(products),dimOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c8e8a400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2/2 [==============================] - 9s 2s/step - loss: 0.2412 - val_loss: 0.3287\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.2319 - val_loss: 0.3269\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos\n",
    "modelo.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "               loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),)\n",
    "\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    modelo.fit(train_dataset, batch_size= batch_size,validation_data= val_dataset, epochs=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
